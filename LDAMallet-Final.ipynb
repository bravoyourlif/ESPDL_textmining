{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A 30% chance of rain tomorrow\": How does the public understand '\n",
      "  'probabilistic weather forecasts?',\n",
      "  'Abstract\\n'\n",
      "  'The weather forecast says that there is a \"30% chance of rain,\" and we '\n",
      "  'think we understand what it means. This quantitative statement is assumed '\n",
      "  'to be unambiguous and to convey more information than does a qualitative '\n",
      "  'statement like \"It might rain tomorrow.\" Because the forecast is expressed '\n",
      "  'as a single-event probability, however, it does not specify the class of '\n",
      "  'events it refers to. Therefore, even numerical probabilities can be '\n",
      "  'interpreted by members of the public in multiple, mutually contradictory '\n",
      "  'ways. To find out whether the same statement about rain probability evokes '\n",
      "  'various interpretations, we randomly surveyed pedestrians in five '\n",
      "  'metropolises located in countries that have had different degrees of '\n",
      "  'exposure to probabilistic forecasts--Amsterdam, Athens, Berlin, Milan, and '\n",
      "  'New York. They were asked what a \"30% chance of rain tomorrow\" means both '\n",
      "  'in a multiple-choice and a free-response format. Only in New York did a '\n",
      "  'majority of them supply the standard meteorological interpretation, namely, '\n",
      "  'that when the weather conditions are like today, in 3 out of 10 cases there '\n",
      "  'will be (at least a trace of) rain the next day. In each of the European '\n",
      "  'cities, this alternative was judged as the least appropriate. The preferred '\n",
      "  'interpretation in Europe was that it will rain tomorrow \"30% of the time,\" '\n",
      "  'followed by \"in 30% of the area.\" To improve risk communication with the '\n",
      "  'public, experts need to specify the reference class, that is, the class of '\n",
      "  'events to which a single-event probability refers.',\n",
      "  'Keywords\\n'\n",
      "  '\\n'\n",
      "  'Author Keywords:cultural differences; risk communication; single-event '\n",
      "  'probabilities; weather forecasts\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  'KeyWords Plus:RISK COMMUNICATION',\n",
      "  2005]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import os\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "os.environ['MALLET_HOME'] = 'C:/Users/user/Desktop/mallet-2.0.8'\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['large','larger','small','smaller','time','higher','significant','highest','important','major','from', 're', 'edu','disaster','risk','hazard','keyword','make','makes','maked','author','study','studying','research','article','articles','review','issue','event','events','occurs','occur','results','resulted','result','case','keywords','disasters','hazards','problem','problems','project','projects','report','reports','reporting','people','pre','base','paper','papers','area','areas','crisis','year','years','day','days','parameter','parameters','base','based','provided','provide','providing','relate','related','due','part','parts','follow','follows','followed','following','high','low','result','results','find','finds','found','field','fields','show','shows','nkeyword','nkeywords'])\n",
    "\n",
    "# Import data\n",
    "with codecs.open('Article(Global)/global_final.json', 'r', 'utf-8-sig') as json_file:  \n",
    "    df= pd.DataFrame(json.load(json_file))\t\n",
    "df.head()\n",
    "\n",
    "# Convert to list\n",
    "data = df.values.tolist()\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chance', 'of', 'rain', 'tomorrow', 'how', 'does', 'the', 'public', 'understand', 'probabilistic', 'weather', 'forecasts', 'abstract', 'nthe', 'weather', 'forecast', 'says', 'that', 'there', 'is', 'chance', 'of', 'rain', 'and', 'we', 'think', 'we', 'understand', 'what', 'it', 'means', 'this', 'quantitative', 'statement', 'is', 'assumed', 'to', 'be', 'unambiguous', 'and', 'to', 'convey', 'more', 'information', 'than', 'does', 'qualitative', 'statement', 'like', 'it', 'might', 'rain', 'tomorrow', 'because', 'the', 'forecast', 'is', 'expressed', 'as', 'single', 'event', 'probability', 'however', 'it', 'does', 'not', 'specify', 'the', 'class', 'of', 'events', 'it', 'refers', 'to', 'therefore', 'even', 'numerical', 'probabilities', 'can', 'be', 'interpreted', 'by', 'members', 'of', 'the', 'public', 'in', 'multiple', 'mutually', 'contradictory', 'ways', 'to', 'find', 'out', 'whether', 'the', 'same', 'statement', 'about', 'rain', 'probability', 'evokes', 'various', 'interpretations', 'we', 'randomly', 'surveyed', 'pedestrians', 'in', 'five', 'metropolises', 'located', 'in', 'countries', 'that', 'have', 'had', 'different', 'degrees', 'of', 'exposure', 'to', 'probabilistic', 'forecasts', 'amsterdam', 'athens', 'berlin', 'milan', 'and', 'new', 'york', 'they', 'were', 'asked', 'what', 'chance', 'of', 'rain', 'tomorrow', 'means', 'both', 'in', 'multiple', 'choice', 'and', 'free', 'response', 'format', 'only', 'in', 'new', 'york', 'did', 'majority', 'of', 'them', 'supply', 'the', 'standard', 'meteorological', 'interpretation', 'namely', 'that', 'when', 'the', 'weather', 'conditions', 'are', 'like', 'today', 'in', 'out', 'of', 'cases', 'there', 'will', 'be', 'at', 'least', 'trace', 'of', 'rain', 'the', 'next', 'day', 'in', 'each', 'of', 'the', 'european', 'cities', 'this', 'alternative', 'was', 'judged', 'as', 'the', 'least', 'appropriate', 'the', 'preferred', 'interpretation', 'in', 'europe', 'was', 'that', 'it', 'will', 'rain', 'tomorrow', 'of', 'the', 'time', 'followed', 'by', 'in', 'of', 'the', 'area', 'to', 'improve', 'risk', 'communication', 'with', 'the', 'public', 'experts', 'need', 'to', 'specify', 'the', 'reference', 'class', 'that', 'is', 'the', 'class', 'of', 'events', 'to', 'which', 'single', 'event', 'probability', 'refers', 'keywords', 'nauthor', 'keywords', 'cultural', 'differences', 'risk', 'communication', 'single', 'event', 'probabilities', 'weather', 'forecasts', 'nkeywords', 'plus', 'risk', 'communication']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chance', 'of', 'rain', 'tomorrow', 'how', 'does', 'the', 'public', 'understand', 'probabilistic', 'weather', 'forecasts', 'abstract_nthe', 'weather', 'forecast', 'says', 'that', 'there', 'is', 'chance', 'of', 'rain', 'and', 'we', 'think', 'we', 'understand', 'what', 'it', 'means', 'this', 'quantitative', 'statement', 'is', 'assumed', 'to', 'be', 'unambiguous', 'and', 'to', 'convey', 'more', 'information', 'than', 'does', 'qualitative', 'statement', 'like', 'it', 'might', 'rain', 'tomorrow', 'because', 'the', 'forecast', 'is', 'expressed', 'as', 'single', 'event', 'probability', 'however', 'it', 'does_not', 'specify', 'the', 'class', 'of', 'events', 'it', 'refers', 'to', 'therefore', 'even', 'numerical', 'probabilities', 'can', 'be', 'interpreted', 'by', 'members', 'of', 'the', 'public', 'in', 'multiple', 'mutually', 'contradictory', 'ways', 'to', 'find', 'out', 'whether', 'the', 'same', 'statement', 'about', 'rain', 'probability', 'evokes', 'various', 'interpretations', 'we', 'randomly', 'surveyed', 'pedestrians', 'in', 'five', 'metropolises', 'located', 'in', 'countries', 'that', 'have', 'had', 'different', 'degrees', 'of', 'exposure', 'to', 'probabilistic', 'forecasts', 'amsterdam', 'athens', 'berlin', 'milan', 'and', 'new_york', 'they', 'were', 'asked', 'what', 'chance', 'of', 'rain', 'tomorrow', 'means', 'both', 'in', 'multiple', 'choice', 'and', 'free', 'response', 'format', 'only', 'in', 'new_york', 'did', 'majority', 'of', 'them', 'supply', 'the', 'standard', 'meteorological', 'interpretation', 'namely', 'that', 'when', 'the', 'weather', 'conditions', 'are', 'like', 'today', 'in', 'out', 'of', 'cases', 'there', 'will', 'be', 'at', 'least', 'trace', 'of', 'rain', 'the', 'next', 'day', 'in', 'each', 'of', 'the', 'european', 'cities', 'this', 'alternative', 'was', 'judged', 'as', 'the', 'least', 'appropriate', 'the', 'preferred', 'interpretation', 'in', 'europe', 'was', 'that', 'it', 'will', 'rain', 'tomorrow', 'of', 'the', 'time', 'followed', 'by', 'in', 'of', 'the', 'area', 'to', 'improve', 'risk', 'communication', 'with', 'the', 'public', 'experts', 'need', 'to', 'specify', 'the', 'reference', 'class', 'that', 'is', 'the', 'class', 'of', 'events', 'to', 'which', 'single', 'event', 'probability', 'refers', 'keywords', 'nauthor', 'keywords', 'cultural', 'differences', 'risk', 'communication', 'single', 'event', 'probabilities', 'weather', 'forecasts', 'nkeywords', 'plus', 'risk', 'communication']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chance', 'rain', 'tomorrow', 'public', 'understand', 'probabilistic', 'weather', 'forecast', 'weather', 'forecast', 'say', 'chance', 'rain', 'think', 'mean', 'quantitative', 'statement', 'assume', 'unambiguous', 'qualitative', 'statement', 'may', 'rain', 'tomorrow', 'forecast', 'express', 'single', 'probability', 'however', 'specify', 'class', 'refer', 'therefore', 'even', 'numerical', 'probability', 'interpret', 'member', 'public', 'multiple', 'mutually', 'contradictory', 'way', 'statement', 'rain', 'probability', 'evoke', 'various', 'interpretation', 'randomly', 'survey', 'pedestrian', 'metropolis', 'locate', 'country', 'different', 'degree', 'exposure', 'probabilistic', 'forecast', 'ask', 'chance', 'rain', 'tomorrow', 'mean', 'multiple', 'choice', 'free', 'response', 'format', 'majority', 'supply', 'standard', 'meteorological', 'interpretation', 'namely', 'weather', 'condition', 'today', 'case', 'least', 'trace', 'rain', 'european', 'city', 'alternative', 'judge', 'least', 'appropriate', 'prefer', 'rain', 'tomorrow', 'improve', 'communication', 'public', 'expert', 'nee', 'specify', 'reference', 'class', 'class', 'single', 'probability', 'refer', 'cultural', 'difference', 'communication', 'single', 'probability', 'weather', 'forecast', 'communication']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 3), (9, 3), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 5), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 2), (47, 5), (48, 3), (49, 1), (50, 1), (51, 7), (52, 1), (53, 2), (54, 1), (55, 1), (56, 1), (57, 3), (58, 2), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 4), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 4)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.075*\"vulnerability\" + 0.054*\"community\" + 0.051*\"resilience\" + '\n",
      "  '0.045*\"social\" + 0.037*\"natural\" + 0.021*\"adaptation\" + 0.015*\"indicator\" + '\n",
      "  '0.015*\"approach\" + 0.014*\"local\" + 0.013*\"framework\"'),\n",
      " (1,\n",
      "  '0.053*\"loss\" + 0.041*\"impact\" + 0.035*\"economic\" + 0.025*\"cost\" + '\n",
      "  '0.020*\"effect\" + 0.016*\"increase\" + 0.016*\"country\" + 0.015*\"reduce\" + '\n",
      "  '0.015*\"global\" + 0.014*\"reduction\"'),\n",
      " (2,\n",
      "  '0.038*\"safety\" + 0.024*\"fire\" + 0.019*\"accident\" + 0.017*\"number\" + '\n",
      "  '0.016*\"activity\" + 0.014*\"work\" + 0.013*\"human\" + 0.011*\"environment\" + '\n",
      "  '0.009*\"potential\" + 0.009*\"type\"'),\n",
      " (3,\n",
      "  '0.032*\"evacuation\" + 0.031*\"recovery\" + 0.022*\"household\" + 0.022*\"affect\" '\n",
      "  '+ 0.021*\"post\" + 0.021*\"population\" + 0.020*\"hurricane\" + 0.019*\"resident\" '\n",
      "  '+ 0.017*\"experience\" + 0.016*\"survey\"'),\n",
      " (4,\n",
      "  '0.027*\"risk\" + 0.023*\"policy\" + 0.013*\"expert\" + 0.013*\"process\" + '\n",
      "  '0.013*\"public\" + 0.013*\"decision\" + 0.011*\"science\" + 0.011*\"environmental\" '\n",
      "  '+ 0.010*\"scientific\" + 0.009*\"evidence\"'),\n",
      " (5,\n",
      "  '0.099*\"system\" + 0.031*\"network\" + 0.026*\"design\" + 0.024*\"develop\" + '\n",
      "  '0.023*\"infrastructure\" + 0.020*\"management\" + 0.018*\"critical\" + '\n",
      "  '0.015*\"performance\" + 0.014*\"propose\" + 0.012*\"approach\"'),\n",
      " (6,\n",
      "  '0.087*\"information\" + 0.029*\"response\" + 0.028*\"communication\" + '\n",
      "  '0.021*\"decision\" + 0.019*\"technology\" + 0.017*\"medium\" + 0.014*\"warning\" + '\n",
      "  '0.012*\"threat\" + 0.011*\"security\" + 0.011*\"present\"'),\n",
      " (7,\n",
      "  '0.039*\"exposure\" + 0.028*\"health\" + 0.018*\"estimate\" + 0.015*\"food\" + '\n",
      "  '0.014*\"response\" + 0.014*\"population\" + 0.013*\"human\" + 0.012*\"dose\" + '\n",
      "  '0.012*\"concentration\" + 0.011*\"level\"'),\n",
      " (8,\n",
      "  '0.026*\"soil\" + 0.020*\"wave\" + 0.015*\"flow\" + 0.013*\"surface\" + '\n",
      "  '0.013*\"failure\" + 0.013*\"slope\" + 0.012*\"water\" + 0.011*\"erosion\" + '\n",
      "  '0.011*\"stress\" + 0.010*\"structure\"'),\n",
      " (9,\n",
      "  '0.194*\"model\" + 0.032*\"datum\" + 0.027*\"distribution\" + 0.025*\"simulation\" + '\n",
      "  '0.025*\"estimate\" + 0.022*\"prediction\" + 0.014*\"predict\" + 0.013*\"method\" + '\n",
      "  '0.012*\"compare\" + 0.012*\"simulate\"'),\n",
      " (10,\n",
      "  '0.110*\"earthquake\" + 0.044*\"damage\" + 0.040*\"building\" + 0.039*\"seismic\" + '\n",
      "  '0.030*\"site\" + 0.025*\"region\" + 0.018*\"source\" + 0.017*\"structure\" + '\n",
      "  '0.014*\"fault\" + 0.013*\"magnitude\"'),\n",
      " (11,\n",
      "  '0.130*\"flood\" + 0.038*\"water\" + 0.037*\"level\" + 0.032*\"urban\" + '\n",
      "  '0.031*\"change\" + 0.024*\"coastal\" + 0.021*\"land\" + 0.020*\"impact\" + '\n",
      "  '0.020*\"damage\" + 0.017*\"increase\"'),\n",
      " (12,\n",
      "  '0.051*\"perception\" + 0.022*\"public\" + 0.020*\"behavior\" + 0.020*\"perceive\" + '\n",
      "  '0.019*\"individual\" + 0.018*\"influence\" + 0.017*\"risk\" + 0.015*\"effect\" + '\n",
      "  '0.014*\"trust\" + 0.012*\"survey\"'),\n",
      " (13,\n",
      "  '0.047*\"landslide\" + 0.031*\"map\" + 0.030*\"factor\" + 0.029*\"datum\" + '\n",
      "  '0.028*\"spatial\" + 0.020*\"analysis\" + 0.018*\"index\" + 0.012*\"method\" + '\n",
      "  '0.011*\"scale\" + 0.010*\"database\"'),\n",
      " (14,\n",
      "  '0.081*\"assessment\" + 0.060*\"analysis\" + 0.038*\"method\" + 0.035*\"approach\" + '\n",
      "  '0.030*\"probability\" + 0.029*\"uncertainty\" + 0.023*\"evaluation\" + '\n",
      "  '0.020*\"propose\" + 0.017*\"evaluate\" + 0.017*\"methodology\"'),\n",
      " (15,\n",
      "  '0.065*\"management\" + 0.030*\"emergency\" + 0.021*\"preparedness\" + '\n",
      "  '0.021*\"government\" + 0.020*\"local\" + 0.018*\"response\" + 0.017*\"plan\" + '\n",
      "  '0.014*\"reduction\" + 0.012*\"action\" + 0.012*\"planning\"'),\n",
      " (16,\n",
      "  '0.034*\"drought\" + 0.030*\"rainfall\" + 0.021*\"extreme\" + 0.019*\"period\" + '\n",
      "  '0.018*\"storm\" + 0.018*\"region\" + 0.016*\"increase\" + 0.016*\"wind\" + '\n",
      "  '0.016*\"precipitation\" + 0.016*\"weather\"')]\n"
     ]
    }
   ],
   "source": [
    "mallet_path = 'C:/Users/user/Desktop/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=17, id2word=id2word)\n",
    "# Show Topics\n",
    "#pprint(ldamallet.show_topics(formatted=False))\n",
    "pprint(ldamallet.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.511918914454681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:223: RuntimeWarning: divide by zero encountered in log\n",
      "  kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:240: RuntimeWarning: divide by zero encountered in log\n",
      "  log_lift = np.log(topic_term_dists / term_proportion)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:241: RuntimeWarning: divide by zero encountered in log\n",
      "  log_ttd = np.log(topic_term_dists)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, id2word)\n",
    "vis\n",
    "pyLDAvis.save_html(vis, 'global_journals.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=25, step=3)\n",
    "\n",
    "# Show graph\n",
    "limit=25; start=2; step=3;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3848\n",
      "Num Topics = 5  has Coherence Value of 0.485\n",
      "Num Topics = 8  has Coherence Value of 0.5163\n",
      "Num Topics = 11  has Coherence Value of 0.523\n",
      "Num Topics = 14  has Coherence Value of 0.5195\n",
      "Num Topics = 17  has Coherence Value of 0.5145\n",
      "Num Topics = 20  has Coherence Value of 0.5207\n",
      "Num Topics = 23  has Coherence Value of 0.5281\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.126*\"community\" + 0.102*\"resilience\" + 0.031*\"local\" + 0.023*\"social\" + '\n",
      "  '0.021*\"adaptation\" + 0.020*\"capacity\" + 0.018*\"approach\" + '\n",
      "  '0.016*\"knowledge\" + 0.014*\"practice\" + 0.013*\"framework\"'),\n",
      " (1,\n",
      "  '0.024*\"water\" + 0.024*\"control\" + 0.015*\"result\" + 0.012*\"effect\" + '\n",
      "  '0.011*\"failure\" + 0.011*\"test\" + 0.011*\"structure\" + 0.011*\"accident\" + '\n",
      "  '0.010*\"condition\" + 0.010*\"mechanism\"'),\n",
      " (2,\n",
      "  '0.042*\"event\" + 0.034*\"region\" + 0.028*\"drought\" + 0.023*\"high\" + '\n",
      "  '0.021*\"extreme\" + 0.018*\"show\" + 0.018*\"result\" + 0.017*\"index\" + '\n",
      "  '0.015*\"climate\" + 0.015*\"pattern\"'),\n",
      " (3,\n",
      "  '0.016*\"humanitarian\" + 0.014*\"implication\" + 0.014*\"purpose\" + '\n",
      "  '0.013*\"study\" + 0.013*\"approach\" + 0.012*\"article\" + 0.012*\"practice\" + '\n",
      "  '0.011*\"context\" + 0.010*\"evidence\" + 0.010*\"literature\"'),\n",
      " (4,\n",
      "  '0.055*\"preparedness\" + 0.041*\"perception\" + 0.033*\"household\" + '\n",
      "  '0.027*\"resident\" + 0.027*\"experience\" + 0.027*\"survey\" + 0.022*\"influence\" '\n",
      "  '+ 0.021*\"individual\" + 0.020*\"factor\" + 0.018*\"level\"'),\n",
      " (5,\n",
      "  '0.096*\"health\" + 0.049*\"preparedness\" + 0.033*\"care\" + 0.032*\"public\" + '\n",
      "  '0.029*\"hospital\" + 0.022*\"medical\" + 0.019*\"emergency\" + 0.017*\"patient\" + '\n",
      "  '0.016*\"service\" + 0.012*\"report\"'),\n",
      " (6,\n",
      "  '0.153*\"earthquake\" + 0.092*\"damage\" + 0.042*\"building\" + 0.022*\"seismic\" + '\n",
      "  '0.018*\"fire\" + 0.015*\"build\" + 0.015*\"structural\" + 0.015*\"site\" + '\n",
      "  '0.013*\"tsunami\" + 0.011*\"large\"'),\n",
      " (7,\n",
      "  '0.040*\"population\" + 0.028*\"increase\" + 0.024*\"exposure\" + 0.022*\"event\" + '\n",
      "  '0.022*\"number\" + 0.022*\"hurricane\" + 0.021*\"compare\" + 0.020*\"relate\" + '\n",
      "  '0.018*\"rate\" + 0.018*\"high\"'),\n",
      " (8,\n",
      "  '0.135*\"system\" + 0.031*\"design\" + 0.030*\"base\" + 0.026*\"develop\" + '\n",
      "  '0.023*\"management\" + 0.019*\"improve\" + 0.016*\"prevention\" + '\n",
      "  '0.015*\"integrate\" + 0.014*\"function\" + 0.013*\"environment\"'),\n",
      " (9,\n",
      "  '0.048*\"network\" + 0.036*\"infrastructure\" + 0.030*\"relief\" + '\n",
      "  '0.026*\"critical\" + 0.018*\"resource\" + 0.018*\"service\" + 0.016*\"time\" + '\n",
      "  '0.014*\"model\" + 0.013*\"affect\" + 0.013*\"supply\"'),\n",
      " (10,\n",
      "  '0.124*\"model\" + 0.058*\"landslide\" + 0.019*\"simulation\" + 0.018*\"result\" + '\n",
      "  '0.017*\"rainfall\" + 0.015*\"prediction\" + 0.014*\"base\" + 0.012*\"debris_flow\" '\n",
      "  '+ 0.012*\"analysis\" + 0.011*\"slope\"'),\n",
      " (11,\n",
      "  '0.032*\"group\" + 0.030*\"support\" + 0.026*\"education\" + 0.024*\"child\" + '\n",
      "  '0.022*\"training\" + 0.021*\"program\" + 0.021*\"experience\" + 0.020*\"school\" + '\n",
      "  '0.018*\"knowledge\" + 0.018*\"mental\"'),\n",
      " (12,\n",
      "  '0.056*\"reduction\" + 0.047*\"policy\" + 0.044*\"management\" + '\n",
      "  '0.042*\"development\" + 0.026*\"country\" + 0.020*\"government\" + '\n",
      "  '0.020*\"project\" + 0.018*\"risk\" + 0.018*\"mitigation\" + 0.018*\"national\"'),\n",
      " (13,\n",
      "  '0.167*\"flood\" + 0.047*\"urban\" + 0.027*\"change\" + 0.026*\"city\" + '\n",
      "  '0.023*\"event\" + 0.021*\"coastal\" + 0.021*\"impact\" + 0.017*\"flooding\" + '\n",
      "  '0.015*\"mitigation\" + 0.015*\"due\"'),\n",
      " (14,\n",
      "  '0.079*\"recovery\" + 0.054*\"loss\" + 0.044*\"economic\" + 0.041*\"impact\" + '\n",
      "  '0.041*\"post\" + 0.030*\"reconstruction\" + 0.022*\"housing\" + 0.022*\"natural\" + '\n",
      "  '0.019*\"insurance\" + 0.015*\"sector\"'),\n",
      " (15,\n",
      "  '0.041*\"approach\" + 0.039*\"process\" + 0.028*\"base\" + 0.028*\"evaluation\" + '\n",
      "  '0.024*\"develop\" + 0.021*\"framework\" + 0.021*\"tool\" + 0.020*\"analysis\" + '\n",
      "  '0.019*\"propose\" + 0.017*\"decision\"'),\n",
      " (16,\n",
      "  '0.078*\"information\" + 0.052*\"evacuation\" + 0.037*\"communication\" + '\n",
      "  '0.024*\"medium\" + 0.020*\"shelter\" + 0.020*\"technology\" + 0.017*\"time\" + '\n",
      "  '0.015*\"warning\" + 0.014*\"public\" + 0.012*\"source\"'),\n",
      " (17,\n",
      "  '0.077*\"datum\" + 0.068*\"assessment\" + 0.032*\"analysis\" + 0.030*\"base\" + '\n",
      "  '0.023*\"map\" + 0.022*\"spatial\" + 0.018*\"information\" + 0.018*\"scale\" + '\n",
      "  '0.015*\"data\" + 0.014*\"provide\"'),\n",
      " (18,\n",
      "  '0.117*\"vulnerability\" + 0.074*\"natural\" + 0.049*\"social\" + 0.035*\"level\" + '\n",
      "  '0.033*\"factor\" + 0.024*\"impact\" + 0.024*\"indicator\" + 0.023*\"analysis\" + '\n",
      "  '0.021*\"environmental\" + 0.019*\"index\"'),\n",
      " (19,\n",
      "  '0.102*\"emergency\" + 0.099*\"response\" + 0.073*\"management\" + 0.038*\"plan\" + '\n",
      "  '0.028*\"planning\" + 0.021*\"organization\" + 0.021*\"local\" + 0.018*\"agency\" + '\n",
      "  '0.017*\"government\" + 0.014*\"effort\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[6]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(20)\n",
    "\n",
    "import csv\n",
    "# Write to file\n",
    "df_dominant_topic.to_csv('TopicForEachDocument.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()\n",
    "sent_topics_sorteddf_mallet.to_csv('EachTopicText.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics.to_csv('NumDocuofEachTopic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_ready' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-78bd527b466e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdf_topic_sents_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_topics_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mldamallet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_ready' is not defined"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2651b3e09edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get topic weights and dominant topics ------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "# Get topic weights and dominant topics ------------\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_mallet[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_mallet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b867e361bb00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                   prefer_horizontal=1.0)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_mallet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_mallet' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_mallet.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
